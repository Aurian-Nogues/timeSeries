{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marginal, Joint and conditional probabilities review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marginal proability P(A):\n",
    "Probability of an event irrespective of other random variables. <br> \n",
    "If variable is independant -> probability of the event directly <br>\n",
    "If variable is dependant -> probability of event summed over all outcomes dor dependant events (sum rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joint Probability\n",
    "probability of 2 simultaneous events P(A and B) or P(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional probability P(A given B) or P(A|B)\n",
    "Probability of one or more event(s) given the occurence of another event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationships\n",
    "P(A,B) = P(A|B)*P(B) <br>\n",
    "P(A,B) = P(B,A)<br>\n",
    "P(A|B) = P(A,B) / P(B)<br>\n",
    "P(A|B) != P(B|A)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate conditional probability from other conditional probability\n",
    "P(A|B) = P(B|A) * P(A) / P(B) <br>\n",
    "P(B|A) = P(A|B) * P(B) / P(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Theorem\n",
    "It is often the case that we don't have access to the joint probability. <br>\n",
    "Bayes' Theorem allows to calculate conditional probability without joing probability <br>\n",
    "It also allows to calculate conditional probability without access to P(B) <br>\n",
    "P(B) = P(B|A) * P(A) + P(B|not A) * P(not A) <br>\n",
    "P(A|B) = P(B|A) * P(A) / (P(B|A) * P(A) + P(B|not A) * P(not A)) <br>\n",
    "with P(not A) = 1-P(A) and P(B|not A) = 1 - P(not B|not A)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naming\n",
    "Naming convention depends on context: <br>\n",
    "P(A|B): Posterior probability <br>\n",
    "P(A): Prior probability <br>\n",
    "P(B|A): Likelihood <br>\n",
    "P(B): Evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the probability that there is fire given that there is smoke? <br>\n",
    "Where P(Fire) is the Prior, P(Smoke|Fire) is the Likelihood, and P(Smoke) is the evidence:<br>\n",
    "P(Fire|Smoke) = P(Smoke|Fire) * P(Fire) / P(Smoke)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancer patient test\n",
    "#### Initial Conditions\n",
    "1/Of all people with cancer tested, 85% will test positive <br>\n",
    "P(Test=Positive) | Cancer=True) = 0.85<br>\n",
    "<br>\n",
    "2/1 person in 5000 has cancer<br>\n",
    "P(Cancer=True) = 0.02% <br>\n",
    "<br>\n",
    "3/ Of all people without cancer tested, 95% will test negative <br>\n",
    "P(Test=Negative | Cancer=False) = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formulation\n",
    "P(A|B) = P(B|A) * P(A) / P(B) <br>\n",
    "P(cancer=True | test = Positive) = P(test=Positive | Cancer = True) * P(cancer=True) / P(test = Positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resolution\n",
    "1/ P(cancer=True | test = Positive) = 0.85 * 0.02% / P(test = Positive) <br>\n",
    "<br>\n",
    "2/ We need to determine P(test = Positive) or P(B) <br>\n",
    "P(B) = P(B|A) * P(A) + P(B|not A) * P(not A) <br>\n",
    "P(test = Positive) = P(test = Positive | Cancer = True) * P(cancer = True) + P(test = Positive | Cancer = False) * P(cancer = False) <br>\n",
    "<br>\n",
    "P(B) = (0.85 * 0.02%) + (1-0.95) * (1-0.02%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05016000000000005"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PB = (0.85 * 0.02/100) + (1-0.95) * (1-0.02/100)\n",
    "PB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which gives the following resulition for P(A|B) or <br>\n",
    "P(cancer=True | test = Positive) = P(test=Positive | Cancer = True) * P(cancer=True) / P(test = Positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34%\n"
     ]
    }
   ],
   "source": [
    "P_of_cancer_if_positive = 0.85 * (0.02/100) / PB\n",
    "print( \"{:.2%}\".format(P_of_cancer_if_positive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied to multiple variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, it is very challenging to calculate full Bayes Theorem for classification.<br>\n",
    "The priors for the class and the data are easy to estimate from a training dataset, if the dataset is suitability representative of the broader problem.<br>\n",
    "The conditional probability of the observation based on the class P(data|class) is not feasible unless the number of examples is extraordinarily large, e.g. large enough to effectively estimate the probability distribution for all different possible combinations of values. This is almost never the case, we will not have sufficient coverage of the domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution to using Bayes Theorem for a conditional probability classification model is to simplify the calculation.\n",
    "<br><br>\n",
    "The Bayes Theorem assumes that each input variable is dependent upon all other variables. This is a cause of complexity in the calculation. We can remove this assumption and consider each input variable as being independent from each other.\n",
    "<br><br>\n",
    "This changes the model from a dependent conditional probability model to an independent conditional probability model and dramatically simplifies the calculation.\n",
    "<br><br>\n",
    "This means that we calculate P(data|class) for each input variable separately and multiple the results together, for example:\n",
    "<br><br>\n",
    "P(class | X1, X2, …, Xn) = P(X1|class) * P(X2|class) * … * P(Xn|class) * P(class) / P(data)\n",
    "We can also drop the probability of observing the data as it is a constant for all calculations, for example:\n",
    "<br><br>\n",
    "P(class | X1, X2, …, Xn) = P(X1|class) * P(X2|class) * … * P(Xn|class) * P(class)\n",
    "This simplification of Bayes Theorem is common and widely used for classification predictive modeling problems and is generally referred to as Naive Bayes.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
